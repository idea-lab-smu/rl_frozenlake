{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "neither-saying",
   "metadata": {},
   "source": [
    "참고링크: https://sumniya.tistory.com/4, https://jeinalog.tistory.com/20, http://blog.quantylab.com/rl.html, https://m.blog.naver.com/hongjg3229/221590282094, https://apincan.tistory.com/41, https://passi0n.tistory.com/86, https://engineering-ladder.tistory.com/68, https://mobicon.tistory.com/539    \n",
    "#### 강화학습\n",
    "   - tabular 방식  \n",
    "   - deep learning 방식\n",
    "     - q-value 구하는 것을 딥러닝과 결합한 것이 DQN(=딥러닝을 통해 q-vaule값을 approximate함)\n",
    "     > q-value란?  \n",
    "     > = 최종적으로 받는 모든 보상의 총합  \n",
    "     > <img src=\"https://user-images.githubusercontent.com/47767202/106096240-81685400-6178-11eb-8cb8-e7eae1e050d1.png\" width=\"30%\">  \n",
    "\n",
    "이 외의 강화학습 용어 참고: https://namu.wiki/w/%EA%B0%95%ED%99%94%ED%95%99%EC%8A%B5/%EC%9A%A9%EC%96%B4\n",
    "\n",
    "#### frozen lake\n",
    "OpenAI gym에서 제공하는 강화학습 환경 중 하나. 다른 종류로는 cartPole이 있음.  \n",
    "<img src=\"https://user-images.githubusercontent.com/47767202/106099841-ae1f6a00-617e-11eb-9e18-92b8ae4b5b5d.png\" width=\"30%\">\n",
    "   - environment는 4*4 모양의 언 호수\n",
    "   - state는 start / goal / safe-frozen / dangerous hole  \n",
    "   - action은 up / left / down / right\n",
    "   - reward는 1(goal state일때) 또는 0(그 외 나머지 경우)\n",
    "   - \\+ agent는 environment를 모르는 상태"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-reasoning",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "active-theology",
   "metadata": {},
   "source": [
    "출처: https://passi0n.tistory.com/86  \n",
    "<img src=\"https://user-images.githubusercontent.com/47767202/106238698-a9bd8480-6244-11eb-940a-0d40eea7d159.png\" width=\"80%\">  \n",
    "\n",
    "- tabular방식 = q-table\n",
    "\n",
    "---------\n",
    "\n",
    "출처: https://sumniya.tistory.com/4\n",
    "<img src=\"https://user-images.githubusercontent.com/47767202/106241851-10916c80-624a-11eb-9d4a-ece7dcea58ba.png\" width=\"80%\">\n",
    "\n",
    "- q-table에서 neural network이용한게 q-net\n",
    "\n",
    "--------\n",
    "\n",
    "출처: https://sumniya.tistory.com/19\n",
    "<img src=\"https://user-images.githubusercontent.com/47767202/106242145-92819580-624a-11eb-9a25-98586a6c82da.png\" width=\"80%\">\n",
    "\n",
    "- q-net에서 딥러닝적용한게 DQN\n",
    "\n",
    "------\n",
    "\n",
    "출처: https://mclearninglab.tistory.com/64\n",
    "<img src=\"https://user-images.githubusercontent.com/47767202/106245696-3b7ebf00-6250-11eb-8582-0a0cffffee94.png\" width=\"80%\">\n",
    "\n",
    "- __Q: tabular 방식은 model-free의 q-learning방식?? or 그냥 따로 봐야하는건지??__\n",
    "    - 답: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-dylan",
   "metadata": {},
   "source": [
    "### 1. tabular방식 + frozen lake 환경\n",
    "코드참고링크: https://sumniya.tistory.com/4  \n",
    "설명참고링크: https://www.youtube.com/watch?v=MQ-3QScrFSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "younger-offense",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "related-kinase",
   "metadata": {},
   "outputs": [],
   "source": [
    "env=gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "global-printing",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize table with all zeros\n",
    "Q = np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "valuable-decision",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-lender",
   "metadata": {},
   "source": [
    "Q -Table of FrozenLake env. has a 16 X 4 grid of shape. (one for each block : 16) X (Action : 4) // up, down, left or right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parallel-australia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "------------------------\n",
      "  (Left)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "action: 0\n",
      "state : 4 \n",
      "info : 0.333\n",
      "------------------------\n",
      "  (Down)\n",
      "SFFF\n",
      "\u001b[41mF\u001b[0mHFH\n",
      "FFFH\n",
      "HFFG\n",
      "action: 1\n",
      "state : 4 \n",
      "info : 0.333\n",
      "------------------------\n",
      "  (Right)\n",
      "S\u001b[41mF\u001b[0mFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "action: 2\n",
      "state : 1 \n",
      "info : 0.333\n",
      "------------------------\n",
      "  (Up)\n",
      "\u001b[41mS\u001b[0mFFF\n",
      "FHFH\n",
      "FFFH\n",
      "HFFG\n",
      "action: 3\n",
      "state : 0 \n",
      "info : 0.333\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# 얘는 잠깐 보여주기용\n",
    "observation = env.reset()\n",
    "env.render() # render = 환경을 화면으로 출력해줌\n",
    "print('------------------------')\n",
    "for i in range(env.action_space.n):\n",
    "    action = i\n",
    "    observation, reward, done, info = env.step(action)\n",
    "    env.render()\n",
    "    print('action: %d' %action) # 0: left, 1: down, 2: right, 3: up\n",
    "    print('state : %d \\ninfo : %.3f' %(observation,info['prob']))\n",
    "    print('------------------------')\n",
    "    observation = env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-closure",
   "metadata": {},
   "source": [
    "is_slippery=True\n",
    "- frozen lake라는 환경은 바람도 많이 불고 빙판길을 걸어가다가 미끄러질 수 있는 변수가 많은 환경이기 때문에, agent는 자신이 원하는 곳으로 마음껏 갈 수 있는 것이 아니다.  \n",
    "= stochastic model이다. \n",
    "[이에 관한 설명 링크](https://apincan.tistory.com/41)\n",
    "\n",
    "\n",
    "- -> Q-table을 갱신할 때 새로운 Q값(즉각적인 보상과 다음 상태에서 얻을 수 있는 최대 보상의 합)보다 기존에 구했던 Q값을 더 신뢰하는 방법을 채택"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "chicken-rapid",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set learning parameters\n",
    "lr = .8   # learning rate: 값이 크게 줄을수록 학습 속도가 빨라짐\n",
    "y = .95   # discount factor\n",
    "num_episodes = 2000\n",
    "\n",
    "#create lists to contain total rewards and steps per episode\n",
    "rList = [] # reword list\n",
    "# sList = [] # state list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "opened-mainstream",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_episodes):\n",
    "    s = env.reset() # Reset environment and get first new observation\n",
    "    rAll = 0        # total reward\n",
    "    d = False       # end of precess\n",
    "    j = 0           # step\n",
    "#     print('------<initial state>-------')\n",
    "#     env.render()\n",
    "#     print('state : %d \\ninfo : %.3f' %(s,info['prob']))\n",
    "#     print('----------------------------')\n",
    "    #The Q-Table learning algorithm\n",
    "    while j < 100:\n",
    "        j+=1\n",
    "        \n",
    "        # Choose an action by greedily (with noise) picking from Q table\n",
    "        # 1/ (i+1) factor has the effect of cutting back on randomness\n",
    "        a = np.argmax(Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1)))  \n",
    "        # 원래식은 a = np.armax(Q[s,:])\n",
    "        # -> 한번 Q-table이 완성되고 나면 항상 같은 루트로만 이동하는 문제점\n",
    "        # -> 아직 가보지 않은 더 최적화된 루트를 찾기 위해 랜덤노이즈 이용\n",
    "        \n",
    "        #Get new state and reward of action an agent did from environment\n",
    "        s1, r, d, info = env.step(a)\n",
    "        \n",
    "        # Update Q-Table with new knowledge(=reward)\n",
    "        Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a]) \n",
    "        # 원래식은 Q[s,a] = r + np.max(Q[s1,:])\n",
    "        \n",
    "        rAll += r # add reward \n",
    "        s = s1    # move to next state\n",
    "\n",
    "        # Check some conditions in console\n",
    "#         env.render()\n",
    "#         print('step : ')\n",
    "#         print('action: %d' %a)\n",
    "#         print('state : %d \\ninfo : %.3f' %(s,info['prob']))\n",
    "#         print('----------------------------')\n",
    "        \n",
    "        # check the end of process = hole이거나 goal일때\n",
    "        if d == True:\n",
    "#             if rAll == 1:\n",
    "#                 print('Arrive at goal State!\\n')\n",
    "\n",
    "#             else:\n",
    "#                 print('Arrive at hole. T.T\\n')\n",
    "            break\n",
    "    #jList.append(j)\n",
    "    rList.append(rAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "preceding-batman",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.519\n"
     ]
    }
   ],
   "source": [
    "print (\"Score over time: \" +  str(sum(rList)/num_episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vertical-presence",
   "metadata": {},
   "source": [
    "0.519 * 2000(num of episode) = 1038번 goal에 도착했음을 알 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "everyday-bangkok",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Q-Table Values\n",
      "[[0.151 0.01  0.005 0.004]\n",
      " [0.004 0.    0.    0.173]\n",
      " [0.002 0.004 0.    0.118]\n",
      " [0.001 0.    0.004 0.099]\n",
      " [0.278 0.    0.001 0.001]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.012 0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.001 0.    0.    0.276]\n",
      " [0.003 0.588 0.001 0.   ]\n",
      " [0.212 0.001 0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.   ]\n",
      " [0.    0.003 0.867 0.   ]\n",
      " [0.    0.    0.851 0.   ]\n",
      " [0.    0.    0.    0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print (\"Final Q-Table Values\")\n",
    "print (np.round(Q,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guided-comfort",
   "metadata": {},
   "source": [
    "초기상태 Q-table\n",
    "<img src=\"https://user-images.githubusercontent.com/47767202/106382553-b1775780-6403-11eb-86db-a0ba6f4005d4.png\" width=\"40%\">\n",
    "업데이트중인 Q-table(예시)\n",
    "<img src=\"https://user-images.githubusercontent.com/47767202/106382628-2fd3f980-6404-11eb-8c15-9a8cd3041d5b.png\" width=\"50%\">\n",
    "최종 Q-table(예시)\n",
    "<img src=\"https://user-images.githubusercontent.com/47767202/106382574-d8358e00-6403-11eb-8290-1ec8f0c8908b.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changing-favor",
   "metadata": {},
   "source": [
    "Let me check more detail. I'll get the index of the maximum prob. in every row, then translate to action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "falling-panic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at state, the agent move : \n",
      "['Left', 'Up', 'Up', 'Up', 'Left', 'hole or goal state', 'Right', 'hole or goal state', 'Up', 'Down', 'Left', 'hole or goal state', 'hole or goal state', 'Right', 'Right', 'hole or goal state']\n"
     ]
    }
   ],
   "source": [
    "action_at_state=[]\n",
    "action_set=['Left', 'Down', 'Right', 'Up']\n",
    "for i in range(len(Q)):\n",
    "    if np.sum(Q[i]) == 0:\n",
    "        action_at_state.append('hole or goal state')\n",
    "    else:\n",
    "        idx=np.argmax(Q[i])\n",
    "        action_at_state.append(action_set[idx])\n",
    "print (\"at state, the agent move : \")\n",
    "print (action_at_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regional-tanzania",
   "metadata": {},
   "source": [
    "- Q: 추측한 q-table이 이상하게 나온 이유는 frozen lake가 stochastic model이라서?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-laptop",
   "metadata": {},
   "source": [
    "### -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-expansion",
   "metadata": {},
   "source": [
    "### 2. q-net + frozen lake 환경\n",
    "코드참고링크: https://sumniya.tistory.com/4  \n",
    "설명참고링크: https://www.youtube.com/watch?v=S1Y9eys2bdg&feature=youtu.be"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "virgin-baking",
   "metadata": {},
   "source": [
    "q-table은 복잡한 실제 문제의 경우 큰 연산이 필요함.\n",
    "따라서 table이 아닌 다른 방법으로 q-value를 얻는 방법 연구 -> q-net  \n",
    "q-net: 실제 값을 모두 observe하여 수치화하는 것이 아닌 function approximator로써 data를 얻음  \n",
    "과정: 1\\*16형태의 one-hot vector를 인코딩하여 각 action에 대한 q-value 도출 -> 이 vector는 nn의 알고리즘에 따라 loss function과 back-prop로 weight를 학습 -> vector 업데이트  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "great-frame",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sohyeon\\Anaconda3\\envs\\metarl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\sohyeon\\Anaconda3\\envs\\metarl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\sohyeon\\Anaconda3\\envs\\metarl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\sohyeon\\Anaconda3\\envs\\metarl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\sohyeon\\Anaconda3\\envs\\metarl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\sohyeon\\Anaconda3\\envs\\metarl\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "accredited-indonesia",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "annoying-logan",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "supported-abortion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\sohyeon\\Anaconda3\\envs\\metarl\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#These lines establish the feed-forward part of the network used to choose actions\n",
    "inputs1 = tf.placeholder(shape=[1,16],dtype=tf.float32)\n",
    "# inputs1 = X, 16 = input_size\n",
    "W = tf.Variable(tf.random_uniform([16,4], 0, 0.01))\n",
    "# 16 = input_size, 4 = output_size\n",
    "\n",
    "Q_out = tf.matmul(inputs1, W)\n",
    "predict = tf.argmax(Q_out, 1) # return : index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "neutral-mattress",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Below we obtain the loss by taking the sum of squares difference between the target and prediction Q values.\n",
    "next_Q = tf.placeholder(shape=[1,4],dtype=tf.float32)\n",
    "# next_Q = y, 4 = output_size\n",
    "\n",
    "loss = tf.reduce_sum(tf.square(next_Q - Q_out))\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)# learing by SGD\n",
    "updateModel = trainer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "funny-professional",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent of succesful episodes: 0.4175%\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Set learning parameters\n",
    "y = .99\n",
    "e = 0.1\n",
    "num_episodes = 2000\n",
    "\n",
    "# Create lists to contain total rewards and steps per episode\n",
    "\n",
    "jList = []\n",
    "rList = []\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        # Reset environment and get first new observation\n",
    "        s = env.reset()\n",
    "        rAll = 0\n",
    "        d = False\n",
    "        j = 0\n",
    "        \n",
    "        # The Q-Network\n",
    "        while j < 99:\n",
    "            j+=1\n",
    "            \n",
    "            # Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "            a, all_Q = sess.run([predict,Q_out], feed_dict={inputs1:np.identity(16)[s:s+1]})\n",
    "            if np.random.rand(1) < e:\n",
    "                a[0] = env.action_space.sample()\n",
    "                \n",
    "            # Get new state and reward from environment\n",
    "            s1,r,d,_ = env.step(a[0])\n",
    "            \n",
    "            # Obtain the Q' values by feeding the new state through our network\n",
    "            Q1 = sess.run(Q_out, feed_dict={inputs1:np.identity(16)[s1:s1+1]})\n",
    "            \n",
    "            # Obtain maxQ' and set our target value for chosen action.\n",
    "            max_Q1 = np.max(Q1)\n",
    "            target_Q = all_Q\n",
    "            target_Q[0,a[0]] = r + y*max_Q1\n",
    "            \n",
    "            # Train our network using target and predicted Q values\n",
    "            _, W1 = sess.run([updateModel,W], feed_dict={inputs1:np.identity(16)[s:s+1], next_Q:target_Q})\n",
    "            rAll += r\n",
    "            s = s1\n",
    "            \n",
    "            if d == True:\n",
    "                # Reduce chance of random action as we train the model.\n",
    "                e = 1./((i/50) + 10)\n",
    "                break\n",
    "                \n",
    "        jList.append(j)     # step\n",
    "        rList.append(rAll)  # total reward\n",
    "        \n",
    "print(\"Percent of succesful episodes: \" + str(sum(rList)/num_episodes) + \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serial-jonathan",
   "metadata": {},
   "source": [
    "0.4175 * 2000 = 835번 goal에 도착했음을 알 수 있음  \n",
    "-> q-table보다 성능 떨어짐. 하지만 q-table보다 유연성이 뛰어남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "artistic-analysis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시각화\n",
    "plt.plot(rList)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "junior-saudi",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(jList)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flush-temple",
   "metadata": {},
   "source": [
    "### 3. DQN + frozen lake 환경\n",
    "코드참고링크: https://github.com/wikke/Reinforcement_Learning/blob/master/FrozenLake_DQN.py  \n",
    "설명참고링크: https://www.youtube.com/watch?v=S1Y9eys2bdg&t=32s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-intelligence",
   "metadata": {},
   "source": [
    "딥러닝 적용시 생기는 문제점\n",
    "- correlations between samples\n",
    "- non-stationary targets  \n",
    "\n",
    "해결방법 = DQN\n",
    "- go deep: 네트워크가 깊을수록 좋다\n",
    "- capture and replay: action의 state를 buffer에 저장한 후 랜덤하게 샘플링하여 학습\n",
    "    - correlations between samples 해결\n",
    "- seperate networks: create a target network\n",
    "    - non-stationary targets 해결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "exciting-defeat",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "import random\n",
    "# import logging\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from gym.envs.registration import register, spec\n",
    "from collections import deque\n",
    "from pandas import DataFrame, Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "perfect-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODES = 2048\n",
    "\n",
    "EPSILON = 1.0\n",
    "EPSILON_DECAY = 0.95\n",
    "EPSILON_MIN = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "crucial-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01 \n",
    "GAMMA = 0.9 \n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "beginning-element",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_LEFT = 0\n",
    "ACTION_DOWN = 1\n",
    "ACTION_RIGHT = 2\n",
    "ACTION_UP = 3\n",
    "ACTION_DEFAULT = None\n",
    "ACTION_TEXT = {\n",
    "    ACTION_LEFT: 'left',\n",
    "    ACTION_DOWN: 'down',\n",
    "    ACTION_RIGHT: 'right',\n",
    "    ACTION_UP: 'up'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "defined-geometry",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent():\n",
    "    def __init__(self):\n",
    "        self.env = self._build_env()\n",
    "        self.nb_status = self.env.observation_space.n\n",
    "        self.nb_action = self.env.action_space.n\n",
    "\n",
    "        self.memory = deque(maxlen=2048)\n",
    "\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_env(self):\n",
    "        frozen_lake = 'FrozenLakeNonSlippery4x4-v0'\n",
    "        try:\n",
    "            spec(frozen_lake)\n",
    "        except:\n",
    "            register(id=frozen_lake, entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "                     kwargs={'map_name': '4x4', 'is_slippery': False})\n",
    "        return gym.make(frozen_lake)\n",
    "\n",
    "    def episode(self):\n",
    "        status = self.env.reset()\n",
    "\n",
    "        while True:\n",
    "            # env.render()\n",
    "            action = self._choose_action(status)\n",
    "            next_status, reward, done, info = self.env.step(action)\n",
    "\n",
    "\n",
    "            self.memory.append((status, action, reward, next_status, done))\n",
    "            status = next_status\n",
    "\n",
    "            if done:\n",
    "                break\n",
    "\n",
    "\n",
    "    def _choose_action(self, status, choose_best = False, return_probs = False):\n",
    "        global EPSILON\n",
    "\n",
    "        if_explore = False\n",
    "        if choose_best:\n",
    "            if_explore = False\n",
    "        else:\n",
    "            if_explore = np.random.uniform() < EPSILON\n",
    "\n",
    "        action = ACTION_DEFAULT\n",
    "        if if_explore:\n",
    "            # exploration\n",
    "            action = np.random.choice(self.nb_action)\n",
    "        else:\n",
    "            # exploitation\n",
    "            reward_pred = self.model.predict(self._one_hot_status(status))[0]\n",
    "            action = np.argmax(reward_pred)\n",
    "\n",
    "        if EPSILON > EPSILON_MIN:\n",
    "            EPSILON *= EPSILON_DECAY\n",
    "\n",
    "        return action if not return_probs else (action, reward_pred)\n",
    "\n",
    "    def replay(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "\n",
    "        batches = random.sample(self.memory, BATCH_SIZE)\n",
    "        X = []\n",
    "        y = []\n",
    "        for status, action, reward, next_status, done in batches:\n",
    "            actual_reward = reward\n",
    "\n",
    "            if not done:\n",
    "                next_reward_pred = self.model.predict( self._one_hot_status(next_status))\n",
    "                actual_reward += GAMMA * np.max(next_reward_pred[0])\n",
    "\n",
    "            one_hot_status = self._one_hot_status(status)\n",
    "            reward_pred = self.model.predict(one_hot_status)\n",
    "            reward_pred[0][action] = actual_reward\n",
    "\n",
    "            X.append(one_hot_status[0])\n",
    "            y.append(reward_pred[0])\n",
    "\n",
    "        self.model.train_on_batch(DataFrame(X), DataFrame(y))\n",
    "        # self.model.fit(X, y, epochs=1, verbose=0)\n",
    "\n",
    "    def demo(self):\n",
    "        print(\"\\n---------- DEMO ----------\")\n",
    "        decisions = []\n",
    "        rewards = []\n",
    "        for status in range(self.nb_status):\n",
    "            best_action, reward = self._choose_action(status, choose_best=True, return_probs=True)\n",
    "            decisions.append(best_action)\n",
    "            rewards.append(reward)\n",
    "\n",
    "        for i in range(self.nb_status):\n",
    "            text = ''\n",
    "            if i in (5,7,11,12):\n",
    "                text = 'HOLE'\n",
    "            elif i == 15:\n",
    "                text = 'GOAL'\n",
    "            else:\n",
    "                text = ACTION_TEXT[decisions[i]]\n",
    "\n",
    "            print(\"{0:^7}\".format(text), end='')\n",
    "\n",
    "            if (i + 1) % 4 == 0:\n",
    "                print('\\n')\n",
    "\n",
    "        print('    LEFT          DOWN          RIGHT         UP')\n",
    "        for r in rewards:\n",
    "            print([i for i in r])\n",
    "\n",
    "    def _one_hot_status(self, status):\n",
    "        one_hot_status = np.zeros(self.nb_status)\n",
    "        one_hot_status[status] = 1\n",
    "        one_hot_status = np.expand_dims(one_hot_status, axis=0)\n",
    "        return one_hot_status\n",
    "\n",
    "    def _build_model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(16, input_dim=self.nb_status, activation='relu'))\n",
    "        model.add(Dense(16, activation='relu'))\n",
    "        model.add(Dense(self.nb_action, activation='linear'))\n",
    "\n",
    "        model.compile(loss='mse', optimizer='adadelta')\n",
    "        model.summary()\n",
    "\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "robust-delhi",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    agent = DQNAgent()\n",
    "\n",
    "    for i in range(EPISODES):\n",
    "        agent.episode()\n",
    "        agent.replay()\n",
    "\n",
    "        if (i+1) % 512 == 0:\n",
    "            agent.demo()\n",
    "            # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "crude-circumstances",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 4)                 68        \n",
      "=================================================================\n",
      "Total params: 612\n",
      "Trainable params: 612\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\sohyeon\\Anaconda3\\envs\\metarl\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "\n",
      "---------- DEMO ----------\n",
      " right   up    right  right \n",
      "\n",
      "  up    HOLE   right  HOLE  \n",
      "\n",
      " right  down    up    HOLE  \n",
      "\n",
      " HOLE   right  right  GOAL  \n",
      "\n",
      "    LEFT          DOWN          RIGHT         UP\n",
      "[0.049938038, 0.046543565, 0.050800987, 0.03488608]\n",
      "[0.045584954, -0.017346647, 0.036553342, 0.04772796]\n",
      "[0.05472885, -0.011670787, 0.06281254, 0.026420813]\n",
      "[0.041474253, 0.008583063, 0.041914262, 0.016709961]\n",
      "[0.037585564, 0.04732801, 0.042469915, 0.051683106]\n",
      "[0.05456306, -0.0002111122, 0.108722635, -0.059639398]\n",
      "[-0.11257208, -0.07303928, 0.05776816, -0.037019208]\n",
      "[-0.05758041, 0.04551269, 0.040688455, -0.005787546]\n",
      "[-0.077271305, 0.02092984, 0.060737923, -0.030931223]\n",
      "[0.042713977, 0.0505384, 0.029441139, 0.04622239]\n",
      "[0.029609688, -0.012518719, -0.03310172, 0.070797965]\n",
      "[-0.19548768, -0.0693354, 0.1261323, -0.038092516]\n",
      "[0.0762048, 0.13199933, 0.05863363, 0.085624784]\n",
      "[-0.032816548, 0.04927648, 0.078447334, -0.01049605]\n",
      "[-0.03784184, 0.076025635, 0.08909951, -0.044271003]\n",
      "[0.013634212, 0.034163374, 0.06911576, 0.057103682]\n",
      "\n",
      "---------- DEMO ----------\n",
      " down   left   left   left  \n",
      "\n",
      " down   HOLE   down   HOLE  \n",
      "\n",
      " right  down   down   HOLE  \n",
      "\n",
      " HOLE   right  right  GOAL  \n",
      "\n",
      "    LEFT          DOWN          RIGHT         UP\n",
      "[0.44314712, 0.49390984, 0.29364708, 0.26751262]\n",
      "[0.370176, 0.3356763, 0.26347288, 0.2362496]\n",
      "[0.31699058, 0.2978543, 0.25639296, 0.22309536]\n",
      "[0.28648993, 0.13793628, 0.26965788, 0.23095512]\n",
      "[0.43275145, 0.5426954, 0.28357485, 0.2843969]\n",
      "[0.2724683, 0.35418582, 0.5705488, 0.14693582]\n",
      "[0.009967716, 0.18528277, 0.09917209, -0.0009313151]\n",
      "[0.045026157, 0.41846547, 0.34027758, 0.09097562]\n",
      "[0.19611487, 0.42146558, 0.67236876, 0.16847071]\n",
      "[0.43418, 0.8341769, 0.37101367, 0.27366275]\n",
      "[0.16421063, 0.2435843, -0.06909222, 0.13627914]\n",
      "[-0.1152043, 0.24118963, 0.50662863, 0.080074936]\n",
      "[0.36005464, 0.669582, 0.48868763, 0.27478606]\n",
      "[0.21209289, 0.38979423, 0.9371618, 0.23602793]\n",
      "[0.46241242, 0.55643994, 1.0544705, 0.2793391]\n",
      "[0.2766026, 0.3507116, 0.4625346, 0.28153807]\n",
      "\n",
      "---------- DEMO ----------\n",
      " down   left   down   left  \n",
      "\n",
      " down   HOLE   down   HOLE  \n",
      "\n",
      " right  down   down   HOLE  \n",
      "\n",
      " HOLE   right  right  GOAL  \n",
      "\n",
      "    LEFT          DOWN          RIGHT         UP\n",
      "[0.5657881, 0.59492683, 0.47388896, 0.5150459]\n",
      "[0.52157474, 0.34892437, 0.34161466, 0.50423443]\n",
      "[0.40790144, 0.5206702, 0.36996934, 0.48270318]\n",
      "[0.4069358, 0.34445462, 0.33650687, 0.35597777]\n",
      "[0.6381601, 0.66386485, 0.15836105, 0.43515795]\n",
      "[0.38192233, 0.6714051, 0.6181036, 0.43475786]\n",
      "[0.21464133, 0.5989374, 0.09027981, 0.08610289]\n",
      "[0.1831696, 0.65393037, 0.29423153, 0.28040576]\n",
      "[0.48973617, 0.31920683, 0.7441428, 0.4910432]\n",
      "[0.644063, 0.8122245, 0.38548693, 0.3537103]\n",
      "[0.46111777, 0.86367536, -0.10269149, 0.10578614]\n",
      "[0.0212975, 0.39324135, 0.46235815, 0.30684128]\n",
      "[0.52321005, 0.8739196, 0.4575475, 0.4809992]\n",
      "[0.19841, 0.76620257, 0.91143954, 0.67684]\n",
      "[0.8651768, 0.80558455, 1.0029999, 0.72242355]\n",
      "[0.49645182, 0.42797622, 0.46209309, 0.47630814]\n",
      "\n",
      "---------- DEMO ----------\n",
      " down   left   down   left  \n",
      "\n",
      " down   HOLE   down   HOLE  \n",
      "\n",
      " right  down   down   HOLE  \n",
      "\n",
      " HOLE   right  right  GOAL  \n",
      "\n",
      "    LEFT          DOWN          RIGHT         UP\n",
      "[0.55970293, 0.59541816, 0.45181504, 0.52887505]\n",
      "[0.52455497, 0.18525268, 0.32069114, 0.5014681]\n",
      "[0.37699243, 0.65156126, 0.38808596, 0.51434016]\n",
      "[0.43680423, 0.32707146, 0.35485512, 0.35973617]\n",
      "[0.64882505, 0.6599328, 0.07242985, 0.47574973]\n",
      "[0.38491935, 0.72567016, 0.6646933, 0.42430294]\n",
      "[0.22064325, 0.7586094, 0.16030829, 0.12185539]\n",
      "[0.17401871, 0.6456281, 0.31886515, 0.28110892]\n",
      "[0.5918018, 0.17076403, 0.7353331, 0.5060476]\n",
      "[0.6594464, 0.81080824, 0.5919944, 0.28129777]\n",
      "[0.5403642, 0.8877037, -0.038959548, 0.220344]\n",
      "[0.022450998, 0.38961327, 0.44138974, 0.33058798]\n",
      "[0.49198586, 0.9188656, 0.5069543, 0.48084313]\n",
      "[0.055157185, 0.806041, 0.898239, 0.7229874]\n",
      "[0.8422885, 0.8889509, 0.9951806, 0.7830797]\n",
      "[0.5590575, 0.34662956, 0.4245739, 0.4849826]\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    print('\\nDone')            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signed-warrant",
   "metadata": {},
   "source": [
    "아직 이해중...."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forward-continent",
   "metadata": {},
   "source": [
    "### 4. DDQN + frozen lake 환경\n",
    "코드참고링크: \n",
    "설명참고링크: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-afghanistan",
   "metadata": {},
   "source": [
    "DDQN = double "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cosmetic-ballot",
   "metadata": {},
   "source": [
    "https://sumniya.tistory.com/19\n",
    "https://jsideas.net/dqn/\n",
    "http://khanrc.github.io/RL-DQN.html#dqn\n",
    "https://jsideas.net/dqn/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-looking",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "metarl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
